<!-- streaming.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Facial Expression Recognition with Deep Learning | Thomas M Burrell III</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Inter', sans-serif;
      background-color: #f9fafb;
      color: #111827;
      padding: 20px;
      max-width: 900px;
      margin: auto;
    }
    .centered-header {
      text-align: center;
      margin-bottom: 30px;
    }
    .centered-header img {
      max-width: 100%;
      border-radius: 8px;
      margin-top: 10px;
    }
    a {
      color: #2563eb;
    }

    img {
      max-width: 100%;
      border-radius: 8px;
      margin-bottom: 20px;
    }
    
  </style>
</head>
<body>
  <div class="centered-header">
    <h1>Facial Expression Recognition with Deep Learning</h1>
    <img src="analyze_face.png" alt="Facial Recognition Image">
  </div>

  <p>
     In this project, we explored the power of deep learning to build a facial emotion recognition (FER) system capable of classifying human expressions
     into seven categories: angry, disgust, fear, happy, neutral, sad, and surprise. Using the Kaggle ‚ÄúFacial Expression Recognition‚Äù dataset (~36,000 images),
     we trained convolutional neural networks (CNNs) to detect emotional cues from grayscale facial images.
  </p>
  <p>
    Our goal was to investigate how machine learning can enhance human-computer interaction across industries like healthcare, security, and customer service.
    We experimented with different model architectures and techniques to improve performance and generalization.
  </p>
  <p>
    Key challenges included expression variability across individuals, cultural differences in emotional display, and the ethical implications of FER systems.
    To improve model reliability, we considered further tuning, better computational resources, and creating our own dataset splits for optimal validation.
  </p>
  <p>
    Looking ahead, this work could be extended to real-time video processing for mental health applications or intelligent surveillance‚Äîalways with a 
    strong emphasis on consent and responsible AI use.
  </p>

  <p>
    üìÇ <a href="https://github.com/Thomas-Burrell/Data_Projects/tree/main/Python_Projects/deep_learning_facial_expression_project" target="_blank">View Code on GitHub</a>
  </p>
  <p>
    üîô <a href="index.html">Back to Home</a>
  </p>
</body>
</html>
